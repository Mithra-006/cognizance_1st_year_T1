{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2b7dPYd3DKj9FPEv6q8Y3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mithra-006/cognizance_1st_year_T1/blob/main/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXPaW5pzCWzh",
        "outputId": "2bbcd858-8e65-43c9-f409-e16e93d83532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                  5.1               3.5                1.4               0.2   \n",
            "1                  4.9               3.0                1.4               0.2   \n",
            "2                  4.7               3.2                1.3               0.2   \n",
            "3                  4.6               3.1                1.5               0.2   \n",
            "4                  5.0               3.6                1.4               0.2   \n",
            "..                 ...               ...                ...               ...   \n",
            "145                6.7               3.0                5.2               2.3   \n",
            "146                6.3               2.5                5.0               1.9   \n",
            "147                6.5               3.0                5.2               2.0   \n",
            "148                6.2               3.4                5.4               2.3   \n",
            "149                5.9               3.0                5.1               1.8   \n",
            "\n",
            "     species  \n",
            "0          0  \n",
            "1          0  \n",
            "2          0  \n",
            "3          0  \n",
            "4          0  \n",
            "..       ...  \n",
            "145        2  \n",
            "146        2  \n",
            "147        2  \n",
            "148        2  \n",
            "149        2  \n",
            "\n",
            "[150 rows x 5 columns]\n",
            "No missing values found.\n",
            "LogisticRegression() - Accuracy: 0.9583333333333334 | F1 Score: 0.9572885078457833\n",
            "DecisionTreeClassifier() - Accuracy: 0.95 | F1 Score: 0.9573570426821201\n",
            "SVC(kernel='linear', random_state=42) - Accuracy: 0.95 | F1 Score: 0.9476438834643168\n",
            "Test Set Accuracy: 1.0\n",
            "Test Set F1 Score: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Model Selection for classification with Scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#LOAD THE DATASET\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['species'] = data.target\n",
        "df.to_csv(\"iris.csv\", index=False)\n",
        "print(df)\n",
        "\n",
        "#CHECK THE MISSED DATA\n",
        "if df.isnull().sum().any(): # checking the missed data if any\n",
        "    print(\"Missing values found. Filling with median values.\")\n",
        "    df.fillna(df.median(), inplace=True)\n",
        "else:\n",
        "    print(\"No missing values found.\")\n",
        "\n",
        "#ENCODING THE DATA\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "df['species']=le.fit_transform(df['species'])\n",
        "\n",
        "X=df.drop('species',axis=1)\n",
        "Y=df['species']\n",
        "\n",
        "#TRAINING THE DATA\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42) #training the model by 80-20 split\n",
        "\n",
        "\n",
        "#STANDARDISING THE DATA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)  # standardising the training and testing model\n",
        "X_test=sc.transform(X_test)\n",
        "\n",
        "#LOGISTIC REGRESSION\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr=LogisticRegression() #creation of logistic regression model\n",
        "lr.fit(X_train,Y_train)\n",
        "\n",
        "#DECISIONTREECLASSIFIER\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_gini=DecisionTreeClassifier(criterion=\"gini\") #creation of decisiontreeclassifier model\n",
        "dt_gini.fit(X_train,Y_train)\n",
        "\n",
        "# SUPPORT VECTOR MACHINES\n",
        "from sklearn.svm import SVC\n",
        "svm = SVC(kernel='linear', random_state=42) #creation of support vector machines model\n",
        "svm.fit(X_train, Y_train)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "# CROSS VALIDATION\n",
        "l=[lr,dt_gini,svm]\n",
        "for i in l:\n",
        "  accuracy_scores = cross_val_score(i, X_train,Y_train, cv=5, scoring='accuracy')\n",
        "  f1_scores = cross_val_score(i, X_train,Y_train, cv=5, scoring=make_scorer(f1_score, average='weighted'))\n",
        "  print(f\"{i} - Accuracy: {accuracy_scores.mean()} | F1 Score: {f1_scores.mean()}\")\n",
        "\n",
        "#LOGISTIC REGRESSION IS BEST\n",
        "\n",
        "# since both the accuracy score and f1_score valaue is high for ridge regression, it is the best model which can be taken for further process\n",
        "y_pred = lr.predict(X_test)\n",
        "accuracy = accuracy_score(Y_test, y_pred)\n",
        "f1 = f1_score(Y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Test Set Accuracy: {accuracy}\")\n",
        "print(f\"Test Set F1 Score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ck9cp9bVCbre"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}